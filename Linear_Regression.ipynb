{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关的计算和绘图包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一个线性回归的类\n",
    "该模型训练方法可以通过 fit () 函数中 train_method 参数进行选择，默认使用随机梯度下降法。\n",
    "\n",
    "代价函数使用均方误差函数\n",
    "$$ J(W) =\\frac{1}{2m}[\\sum_{i=1}^m(h_\\theta(x^i)-y^i)^2 + \\lambda\\sum_{j=1}^n\\theta_j^2]  $$\n",
    "参数更新方式推导结果为：\n",
    "$$ W = W*(1-\\alpha\\frac{\\lambda}{m})-\\alpha\\frac{\\lambda}{m}(\\stackrel{\\bigwedge}{Y}-Y)X^T $$\n",
    "$$ b = b*(1-\\alpha\\frac{\\lambda}{m})-\\alpha\\frac{\\lambda}{m}(\\stackrel{\\bigwedge}{Y}-Y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression():\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "        self.bias = None\n",
    "        self.learning_rate = None\n",
    "        self.n_iters = None\n",
    "        \n",
    "    def train_sgd(self, X, Y, m, lam):\n",
    "        '''使用梯度下降方法更新参数'''\n",
    "        Y_hat = np.dot(self.W, X) + self.bias\n",
    "        \n",
    "        # 如果 lam 不为 None，就使用 L2正则化\n",
    "        if lam is None:\n",
    "            # 不适用L2正则化部分\n",
    "            cost = np.sum(np.square(Y_hat - Y)) / 2*m\n",
    "        \n",
    "            dW = np.dot((Y_hat - Y), X.T) / m\n",
    "            db = np.sum(Y_hat - Y) / m\n",
    "            \n",
    "            self.W = self.W - self.learning_rate * dW\n",
    "            self.bias = self.bias - self.learning_rate * db\n",
    "            \n",
    "        else:\n",
    "            # 使用 L2 正则化部分\n",
    "            cost = np.sum(np.square(Y_hat - Y) + lam * np.sum(np.square(self.W))) / 2*m \n",
    "            \n",
    "            dW = np.dot((Y_hat - Y), X.T) / m\n",
    "            db = np.sum(Y_hat - Y) / m\n",
    "            \n",
    "            self.W = self.W * (1 - self.learning_rate * lam / m) - self.learning_rate * dW\n",
    "            self.bias = self.bias * (1 - self.learning_rate *lam / m) - self.learning_rate * db\n",
    "                  \n",
    "        return cost\n",
    "    \n",
    "    def fit(self, X=None, Y=None, learning_rate=0.01, n_iters=100, train_method='sgd', plot_cost=True, lam=None):\n",
    "        '''训练函数'''\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        \n",
    "        # m 为样本个数， n为特征个数, result_dim 每个样本输出的维度\n",
    "        m = X.shape[1]      \n",
    "        n = X.shape[0]\n",
    "        \n",
    "        result_dim = Y.shape[0]\n",
    "        \n",
    "        # 初始化参数\n",
    "        self.W = np.random.normal(size=(result_dim, n))\n",
    "        self.bias = np.zeros((result_dim, 1))\n",
    "        \n",
    "        cost_ls = []\n",
    "        \n",
    "        # 训练阶段\n",
    "        for i in range(self.n_iters):\n",
    "            # 选择训练方法\n",
    "            if train_method == 'sgd':\n",
    "                cost = self.train_sgd(X, Y, m, lam)\n",
    "            cost_ls.append(cost)\n",
    "            \n",
    "        # 如果 plot_cost 为 True，就绘制训练阶段损失函数值得变化曲线图\n",
    "        if plot_cost == True:\n",
    "            plt.plot(np.arange(self.n_iters), cost_ls)\n",
    "            plt.title(\"Loss in Training\")\n",
    "            plt.xlabel(\"iter_num\")\n",
    "            plt.ylabel(\"loss_value\")\n",
    "            plt.show()\n",
    "    \n",
    "    def score(self, X_test, Y_test):\n",
    "        if self.W is None or self.bias is None:\n",
    "            raise NameError(\"未经过训练，参数没值\")\n",
    "        \n",
    "        Y_hat = np.dot(self.W, X_test) + self.bias\n",
    "        square_erros = np.sum(np.square(Y_hat - Y_test)) / 2*Y_test.shape[1]\n",
    "        \n",
    "        return square_erros\n",
    "    \n",
    "    def predict(self, X_pred):\n",
    "        if self.W is None or self.bias is None:\n",
    "            raise NameError(\"未经过训练，参数没值\")\n",
    "        \n",
    "        Y_hat = np.dot(self.W, X_pred) + self.bias\n",
    "        \n",
    "        return Y_hat\n",
    "    \n",
    "    def get_params(self):\n",
    "        '''返回模型参数'''\n",
    "        return self.W, self.bias\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成一维的训练数据和测试数据并测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_dim_data(func, num, std):\n",
    "    x = np.linspace(0, 1, num)\n",
    "    x = np.expand_dims(x, 0)\n",
    "    y = func(x) + np.random.normal(scale=std, size=x.shape)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def func(x):\n",
    "    return 4.8 * x + 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train =gen_one_dim_data(func, 10, 0.25)\n",
    "\n",
    "x_test = np.expand_dims(np.linspace(0, 1, 20), 0)\n",
    "y_test = func(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = Linear_Regression()\n",
    "# 训练， 不使用L2 正则化，lam=None\n",
    "model_linear.fit(x_train, y_train, n_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l2 = Linear_Regression()\n",
    "# 训练，使用L2正则化， lam 设置为 0.01\n",
    "model_l2.fit(x_train, y_train, n_iters=1000, lam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用训练好的模型在训练集上预测\n",
    "pred_train = model_linear.predict(x_train)\n",
    "pred_train_l2 = model_l2.predict(x_train)\n",
    "\n",
    "# 在训练集上绘图\n",
    "plt.title(\"Training data\")\n",
    "plt.xlabel(\"x_train\")\n",
    "plt.ylabel(\"y_train\")\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor='b', s=50, label=\"training_data\")\n",
    "plt.plot(x_train[0], pred_train[0], c='g', label=\"model_pred_train\")\n",
    "plt.plot(x_train[0], pred_train_l2[0], c='r', label=\"model_pred_train_l2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型在测试集上预测\n",
    "pred_test = model_linear.predict(x_test)\n",
    "pred_test_l2 = model_l2.predict(x_test)\n",
    "# 绘制测试集上的真实线，和模型预测线\n",
    "plt.title(\"Test data\")\n",
    "plt.xlabel(\"x_test\")\n",
    "plt.ylabel(\"y_test\")\n",
    "plt.scatter(x_test, y_test, facecolor='none', edgecolor='b', s=50, label='test_data')\n",
    "plt.plot(x_test[0], y_test[0], c='y', label='true_line')\n",
    "plt.plot(x_test[0], pred_test[0], c='r', label='model_pred_test')\n",
    "plt.plot(x_test[0], pred_test_l2[0], c='b', label='model_pred_test_l2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成多维特征的数据训练模型并测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成多维特征数据函数\n",
    "def gen_mul_dim_data(func_mul, feature_n, example_m, std=0.25):\n",
    "    x = np.random.normal(size=(feature_n, example_m))\n",
    "    y_no_nosie, W, bias = func_mul(x)\n",
    "    y = y_no_nosie + np.random.normal(scale=std, size=y_no_nosie.shape)\n",
    "    \n",
    "    return x, y, W, bias\n",
    "\n",
    "def func_mul(x):\n",
    "    W = np.random.normal(size=(1, x.shape[0]))\n",
    "    bias = 7.2\n",
    "    return np.dot(W, x) + bias, W, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, W_train_true, bias_train_true =gen_mul_dim_data(func_mul, 7, 80)\n",
    "\n",
    "x_test = np.random.normal(size=(7, 10))\n",
    "y_test, W_test_true, bias_test_true = func_mul(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul_linear = Linear_Regression()\n",
    "\n",
    "model_mul_linear.fit(x_train, y_train, learning_rate=0.01, n_iters=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul_linear_l2 = Linear_Regression()\n",
    "\n",
    "model_mul_linear_l2.fit(x_train, y_train, learning_rate=0.01, n_iters=800, lam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练集上比较 模型学的的参数与真实参数\n",
    "W_train_model, bias_train_model = model_mul_linear.get_params()\n",
    "print(\"W_train_model    : \", W_train_model)\n",
    "print(\"W_train_true     : \", W_train_true)\n",
    "print(\"bias_train_model : \", bias_train_model)\n",
    "print(\"bias_train_true  : \", bias_train_true)\n",
    "print()\n",
    "print(\"-----------------L2--------------------------------\")\n",
    "W_train_model_l2, bias_train_model_l2 = model_mul_linear_l2.get_params()\n",
    "print(\"W_train_model_l2    : \", W_train_model_l2)\n",
    "print(\"W_train_true     : \", W_train_true)\n",
    "print(\"bias_train_model_l2 : \", bias_train_model_l2)\n",
    "print(\"bias_train_true  : \", bias_train_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上比较 真实值和模型预测值\n",
    "y_pred_test = model_mul_linear.predict(x_test)\n",
    "print(\"pred_test : \", y_pred_test)\n",
    "print(\"true_test : \", y_test)\n",
    "score_test = model_mul_linear.score(x_test, y_test)\n",
    "print(\"loss_on_test : \", score_test)\n",
    "\n",
    "print()\n",
    "print(\"-----------------L2--------------------------------\")\n",
    "y_pred_test_l2 = model_mul_linear_l2.predict(x_test)\n",
    "print(\"pred_test_l2 : \", y_pred_test_l2)\n",
    "print(\"true_test : \", y_test)\n",
    "score_test_l2 = model_mul_linear_l2.score(x_test, y_test)\n",
    "print(\"loss_on_test_l2 : \", score_test_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
